# information for saving and loading files
import numpy as np
import os
import sys
from astropy.io import fits
from astropy.table import Table
from astropy.wcs import WCS
from glob import glob
import pickle
import pandas as pd

### SETUP HERE
# Also check the find_image_path() function and make sure your image names match that string
# Location to save
clustering_folder = '/Users/brianlorenz/uncover/Clustering/' # SET TO YOUR OWN DEVICE
catalogs_folder = '/Users/brianlorenz/uncover/Catalogs/' # SET TO YOUR OWN DEVICE

# Catalog files
SUPER_CATALOG_loc = f'{catalogs_folder}UNCOVER_v5.2.0_LW_SUPER_CATALOG.fits'
sps_loc = f'{catalogs_folder}UNCOVER_v5.3.0_LW_SUPER_SPScatalog_spsv1.0.fits'
segmap_loc = f'{catalogs_folder}UNCOVER_v5.2.0_SEGMAP.fits'
image_folder = f'{catalogs_folder}psf_matched/' # Images should be stored here - see find_image_path() for exact filenames

# ----------------------------------------------------------------- #

# Subfolders of clustering folder - these should get generated by the code
pixel_sed_save_loc = f'{clustering_folder}pixel_seds/'
sed_save_loc = f'{clustering_folder}seds/'
image_save_dir = f'{clustering_folder}images/'
composite_sed_save_dir = f'{clustering_folder}composite_seds/'
composite_image_save_dir = f'{clustering_folder}composite_images/'

# Generated files by this code
uncover_filters_info = clustering_folder+'files/uncover_filters.pkl'
redshift_info = clustering_folder+'files/redshifts.csv'

def find_image_path(filt):
    image_path = glob(image_folder + 'uncover_v7.*'+'*_abell2744clu_*'+filt+'*sci_f444w-matched.fits')
    wht_image_path = glob(image_folder + 'uncover_v7.*'+'*_abell2744clu_*'+filt+'*wht_f444w-matched.fits')
    if len(image_path) > 1:
        sys.exit(f'Error: multiple images found for filter {filt}')
    if len(wht_image_path) < 1:
        sys.exit(f'Error: no image found for filter {filt}')
    image_str = image_path[0]
    wht_image_str = wht_image_path[0]
    return image_str, wht_image_str


def read_saved_pixels(id_dr3):
    pixel_data = np.load(pixel_sed_save_loc + f'{id_dr3}_pixels.npz')
    """
    CONTAINS:
    pixel_seds = pixel_data['pixel_seds'] # shape of (n_images, pixel_ids)
    masked_indicies = pixel_data['masked_indicies'] # shape of (2, pixel_ids)
    image_cutouts = pixel_data['image_cutouts'] # shape of (n_images, cutout_y_size, cutout_x_size)
    noise_cutouts = pixel_data['noise_cutouts'] # shape of (n_images, cutout_y_size, cutout_x_size)
    boolean_segmap = pixel_data['boolean_segmap'] # shape of (cutout_y_size, cutout_x_size)
    obj_segmap = pixel_data['obj_segmap'] # shape of (cutout_y_size, cutout_x_size)
    filter_names = pixel_data['filter_names'] # shape of (n_images,)
    """
    return pixel_data

def read_sed(id_dr3):
    sed_data = np.load(sed_save_loc + f'{id_dr3}_sed.npz')
    """
    CONTAINS:
    # sed = pixel_data['sed']
    # err_sed = pixel_data['err_sed'] 
    """
    return sed_data

def read_supercat():
    supercat_df = make_pd_table_from_fits(SUPER_CATALOG_loc)
    return supercat_df

def read_SPS_cat():
    sps_df = make_pd_table_from_fits(sps_loc)
    return sps_df

def read_segmap():
    with fits.open(segmap_loc) as hdu:
        segmap = hdu[0].data
        segmap_wcs = WCS(hdu[0].header)
    return segmap, segmap_wcs

def make_pd_table_from_fits(file_loc):
    """Read a fits file and turn it into pandas dataframe"""
    with fits.open(file_loc) as hdu:
        data_loc = hdu[1].data
        data_df = Table(data_loc).to_pandas()
        return data_df
    
def get_cluster_save_path(cluster_method, norm_method='', distances='', id_dr3=-1):
    save_path = pixel_sed_save_loc + f'{cluster_method}{norm_method}{distances}/'
    if id_dr3 >= 0:
        save_path = pixel_sed_save_loc + f'{cluster_method}{norm_method}{distances}/{id_dr3}_clustered.npz'
    return save_path

def read_uncover_filters():
    with open(uncover_filters_info, "rb") as f:
        filt_dict = pickle.load(f)
    return filt_dict

def get_wavelength(filt_dict, filt_name):
    wave = filt_dict[filt_name+'_wave_eff']
    return wave

def check_and_make_dir(file_path):
    if not os.path.exists(file_path):
        os.mkdir(file_path)

def store_redshifts():
    sps_df = read_SPS_cat()
    redshift_df = sps_df[['id', 'z_50']]
    check_and_make_dir(clustering_folder+'files/')
    redshift_df.to_csv(redshift_info, index=False)

def read_redshifts():
    if not os.path.exists(redshift_info):
        store_redshifts()
    redshift_df = pd.read_csv(redshift_info)
    return redshift_df



